{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open AI gym - MountainCar\n",
    "\n",
    "### Open AI gym installeerimine\n",
    "\n",
    "Piisab ka `pip3 install gym`, kuid sedasi ei saa k천iki erinevaid keskkondi alla laadida. K천ikide keskkondade installeerimiseks sobib:\n",
    "\n",
    "```\n",
    "git clone https://github.com/openai/gym.git\n",
    "cd gym\n",
    "pip3 install -e .\n",
    "pip3 install -e '.[all]'\n",
    "```\n",
    "\n",
    "Rohkem infot: http://gym.openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install gym tensorflow numpy keyboard matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'marie, m채rten'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{nimi1}, {nimi2}'.format(nimi2='m채rten', nimi1='marie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midagi muud\n"
     ]
    }
   ],
   "source": [
    "x = 5\n",
    "\n",
    "if functsioon():\n",
    "\n",
    "else:\n",
    "    print('midagi muud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "else\n"
     ]
    }
   ],
   "source": [
    "x = \n",
    "\n",
    "if x:\n",
    "    print('if')\n",
    "else:\n",
    "    print('else')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Double DQN (DDQN)\n",
    "- Dueling DQN\n",
    "- Distributional RL\n",
    "- Noisy nets (https://github.com/spring01/drlbox.git)\n",
    "- Prioritized Experience Replay\n",
    "\n",
    "**to do**\n",
    "- N-step Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumTree(object):\n",
    "    data_pointer = 0\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.tree = np.zeros(2 * capacity - 1)\n",
    "        self.data = np.zeros(capacity, dtype=object)\n",
    "    \n",
    "    def add(self, priority, data):\n",
    "        tree_index = self.data_pointer + self.capacity - 1\n",
    "        self.data[self.data_pointer] = data\n",
    "        self.update(tree_index, priority)\n",
    "        self.data_pointer += 1\n",
    "        \n",
    "        if self.data_pointer >= self.capacity:\n",
    "            self.data_pointer = 0\n",
    "\n",
    "    def update(self, tree_index, priority):\n",
    "        change = priority - self.tree[tree_index]\n",
    "        self.tree[tree_index] = priority\n",
    "        \n",
    "        while tree_index != 0:\n",
    "            tree_index = (tree_index - 1) // 2\n",
    "            self.tree[tree_index] += change\n",
    "    \n",
    "    def get_leaf(self, v):\n",
    "        parent_index = 0\n",
    "        while True:\n",
    "            left_child_index = 2 * parent_index + 1\n",
    "            right_child_index = left_child_index + 1\n",
    "            if left_child_index >= len(self.tree):\n",
    "                leaf_index = parent_index\n",
    "                break\n",
    "            else:\n",
    "                if v <= self.tree[left_child_index]:\n",
    "                    parent_index = left_child_index\n",
    "                    \n",
    "                else:\n",
    "                    v -= self.tree[left_child_index]\n",
    "                    parent_index = right_child_index\n",
    "            \n",
    "        data_index = leaf_index - self.capacity + 1\n",
    "        return leaf_index, self.tree[leaf_index], self.data[data_index]\n",
    "    \n",
    "    @property\n",
    "    def total_priority(self):\n",
    "        return self.tree[0]\n",
    "    \n",
    "class Memory(object):\n",
    "    PER_e = 0.01 # min probability\n",
    "    PER_a = 0.6  # 1-a = pr of selecting randomly (ignoring probability)\n",
    "    PER_b = 0.4  # effecy of importance sampling (IS) weights on training\n",
    "    PER_b_increment_per_sampling = 0.001\n",
    "    absolute_error_upper = 1.\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.tree = SumTree(capacity)\n",
    "\n",
    "    def store(self, experience):\n",
    "        max_priority = np.max(self.tree.tree[-self.tree.capacity:])\n",
    "        if max_priority == 0:\n",
    "            max_priority = self.absolute_error_upper\n",
    "        \n",
    "        self.tree.add(max_priority, experience)\n",
    "        \n",
    "    def sample(self, n):\n",
    "        memory_b = []\n",
    "        \n",
    "        b_idx, b_ISWeights = np.empty((n,), dtype=np.int32), np.empty(n, dtype=np.float32)\n",
    "        priority_segment = self.tree.total_priority / n\n",
    "        self.PER_b = np.min([1., self.PER_b + self.PER_b_increment_per_sampling])\n",
    "        p_min = np.min(self.tree.tree[-self.tree.capacity:]) / self.tree.total_priority\n",
    "        max_weight = (p_min * n) ** (-self.PER_b)\n",
    "        \n",
    "        for i in range(n):\n",
    "            a, b = priority_segment * i, priority_segment * (i + 1)\n",
    "            value = np.random.uniform(a, b)\n",
    "            index, priority, data = self.tree.get_leaf(value)\n",
    "            sampling_probabilities = priority / self.tree.total_priority\n",
    "            \n",
    "            b_ISWeights[i] = np.power(n * sampling_probabilities, -self.PER_b) / max_weight\n",
    "            b_idx[i]= index\n",
    "            experience = data\n",
    "            memory_b.append(experience)\n",
    "            \n",
    "        return (b_idx, memory_b, b_ISWeights)\n",
    "\n",
    "    def batch_update(self, tree_idx, abs_errors):\n",
    "        abs_errors += self.PER_e\n",
    "        clipped_errors = np.minimum(abs_errors, self.absolute_error_upper)\n",
    "        ps = np.power(clipped_errors, self.PER_a)\n",
    "\n",
    "        for ti, p in zip(tree_idx, ps):\n",
    "            self.tree.update(ti, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.engine.base_layer import Layer\n",
    "from tensorflow.python.keras.engine.input_spec import InputSpec\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "\n",
    "class NoisyNet(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(NoisyNet, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        def make_noise(shape):\n",
    "            kernel_noise_input = make_fg_noise(shape=[shape[0]])\n",
    "            kernel_noise_output = make_fg_noise(shape=[shape[1]])\n",
    "            kernel_noise = kernel_noise_input[:, tf.newaxis] * kernel_noise_output\n",
    "            return kernel_noise\n",
    "    \n",
    "        def make_fg_noise(shape):\n",
    "            noise = tf.random.normal(shape, dtype=self.dtype)\n",
    "            trans_noise = tf.sign(noise) * tf.sqrt(tf.abs(noise))\n",
    "            return tf.Variable(trans_noise, trainable=False, dtype=self.dtype)\n",
    "        \n",
    "        input_dim = input_shape[-1]\n",
    "        kernel_shape = (1, input_dim)\n",
    "        \n",
    "        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n",
    "        scale_init = init_ops.Constant(value=(0.25 / np.sqrt(input_dim)))\n",
    "        \n",
    "        self.noise_scale = self.add_weight(\n",
    "            name='noise_scale',\n",
    "            shape=kernel_shape,\n",
    "            initializer=scale_init,\n",
    "            dtype=self.dtype,\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        self.noise = make_noise(kernel_shape)\n",
    "                \n",
    "    def call(self, inputs):\n",
    "        training = K.learning_phase()\n",
    "        \n",
    "        def add_noise():\n",
    "            return inputs + self.noise_scale * self.noise\n",
    "        \n",
    "        output = tf_utils.smart_cond(training, add_noise, add_noise)#lambda: array_ops.identity(inputs))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "tfk = tf.keras\n",
    "tfk.backend.clear_session()\n",
    "\n",
    "class AIAgent:\n",
    "    \"\"\"\n",
    "    A simple neural network based AI agent.\n",
    "    \"\"\"\n",
    "    def __init__(self, train, model_weights_dir=None, use_pretrained=False, memory=Memory(500)):\n",
    "        self.train = train\n",
    "        self.train_counter = 0\n",
    "        self.memory_counter = 0\n",
    "        self.memory = memory\n",
    "        self.training_losses = deque(maxlen=10000)\n",
    "        self.previous_state = None\n",
    "        self.model_weights_dir = model_weights_dir\n",
    "        self.use_pretrained = use_pretrained\n",
    "        \n",
    "        self.gamma = 0.99     \n",
    "        self.num_actions = 3\n",
    "        self.num_atoms = 51\n",
    "        self.v_max = round(0.7**2,1)\n",
    "        self.v_min = -0.001\n",
    "        self.delta_z = (self.v_max - self.v_min) / float(self.num_atoms - 1)\n",
    "        self.z = [self.v_min + i * self.delta_z for i in range(self.num_atoms)]\n",
    "        \n",
    "        self.model = self.create_model()\n",
    "        self.target_model = self.create_model()\n",
    "        self.num_samples = 1\n",
    "        \n",
    "    def act(self, obs):\n",
    "        \"\"\"\n",
    "        Outputs model actions given the state.\n",
    "        \"\"\"\n",
    "        obs = self.reshape_single_obs(obs)\n",
    "        z = self.model.predict(obs)\n",
    "        z_concat = np.vstack(z)\n",
    "        q = np.sum(np.multiply(z_concat, np.array(self.z)), axis=1)\n",
    "        q = q.reshape(self.num_actions, order='F')\n",
    "        optimal_action_idxs = np.argmax(q)\n",
    "        \n",
    "        return optimal_action_idxs.tolist()\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Defines the AI model.\n",
    "        \"\"\"\n",
    "        def ddqn_join(input_layers):\n",
    "            value = input_layers[0]\n",
    "            advantage = input_layers[1]\n",
    "            output = value + tf.subtract(advantage, tf.reduce_mean(advantage, axis=-1, keepdims=True))\n",
    "            return output\n",
    "        \n",
    "        state = tfk.layers.Input(shape=(2), name='state')\n",
    "        x = tfk.layers.Dense(32, activation=None, name='fully_connected')(state)\n",
    "        x = NoisyNet(name='noise')(x)\n",
    "        x = tfk.layers.ReLU(name='activation')(x)\n",
    "        \n",
    "        value = tfk.layers.Dense(1, activation=None, name='value')(x)\n",
    "        advantage = tfk.layers.Dense(self.num_actions, activation=None, name='advantage')(x)\n",
    "        ddqn = tfk.layers.Lambda(ddqn_join, name='ddqn')([value, advantage])\n",
    "        \n",
    "        distribution_list = []\n",
    "        for i in range(self.num_actions): \n",
    "            distribution_list.append(tfk.layers.Dense(self.num_atoms, activation='softmax', name='action_'+str(i))(ddqn))\n",
    "        \n",
    "        model = tfk.Model(inputs=state, outputs=distribution_list, name='rainbow')\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=tfk.optimizers.Adam(lr=1e-2))\n",
    "        \n",
    "        if self.use_pretrained and self.model_weights_dir:\n",
    "            model.load_weights(self.model_weights_dir)\n",
    "            \n",
    "        return model\n",
    "        \n",
    "    def save_memory(self, obs, reward, action, done):\n",
    "        \"\"\"\n",
    "        Save episodes and Q values for training the model.\n",
    "        \"\"\"\n",
    "        obs = self.reshape_single_obs(obs)\n",
    "        \n",
    "        if self.previous_state:\n",
    "                        \n",
    "            z = self.model.predict(obs)\n",
    "            z_ = self.target_model.predict(obs)\n",
    "        \n",
    "            z_concat = np.vstack(z)\n",
    "            q = np.sum(np.multiply(z_concat, np.array(self.z)), axis=1)\n",
    "            q = q.reshape((self.num_samples, self.num_actions), order='F')\n",
    "            optimal_action_idxs = np.argmax(q, axis=1)\n",
    "            \n",
    "            m_prob = [np.zeros((self.num_samples, self.num_atoms)) for i in range(self.num_actions)]\n",
    "            if done:\n",
    "                Tz = min(self.v_max, max(self.v_min, reward))\n",
    "                bj = (Tz - self.v_min) / self.delta_z \n",
    "                m_l, m_u = np.floor(bj), np.ceil(bj)\n",
    "                m_prob[action][0][int(m_l)] += (m_u - bj)\n",
    "                m_prob[action][0][int(m_u)] += (bj - m_l)\n",
    "            else:\n",
    "                for j in range(self.num_atoms):\n",
    "                    Tz = min(self.v_max, max(self.v_min, reward + self.gamma * self.z[j]))\n",
    "                    bj = (Tz - self.v_min) / self.delta_z \n",
    "                    m_l, m_u = np.floor(bj), np.ceil(bj)\n",
    "                    m_prob[action][0][int(m_l)] += z_[optimal_action_idxs[0]][0][j] * (m_u - bj)\n",
    "                    m_prob[action][0][int(m_u)] += z_[optimal_action_idxs[0]][0][j] * (bj - m_l)            \n",
    "            \n",
    "            self.memory.store((self.previous_state['obs'], m_prob))\n",
    "            self.memory_counter += 1\n",
    "            \n",
    "        # train model on batch if memory is populated\n",
    "        if self.train and self.memory_counter >= self.memory.tree.capacity:\n",
    "            self.train_model()\n",
    "        \n",
    "        # reset prev state if episode is completed, else update\n",
    "        if done:\n",
    "            self.previous_state = None\n",
    "        else:\n",
    "            self.previous_state = {\n",
    "                'obs': obs,\n",
    "                'reward': reward,\n",
    "                'action': action\n",
    "            }\n",
    "            \n",
    "    def train_model(self, batch_size=32):\n",
    "        \"\"\"\n",
    "        Trains the model on minibatch.\n",
    "        \"\"\"\n",
    "        # sample random episides from memory\n",
    "        b_idx, batch, b_ISWeights = self.memory.sample(batch_size)\n",
    "                \n",
    "        self.train_counter += 1\n",
    "        X = []\n",
    "        y = []\n",
    "        for row in batch:\n",
    "            X.append(row[0])\n",
    "            y.append(row[1])\n",
    "        X = np.vstack(X)\n",
    "        y = np.hstack(y)\n",
    "        y = [y[i] for i in range(y.shape[0])]\n",
    "        \n",
    "        sample_weights = {}\n",
    "        for i in range(self.num_actions):\n",
    "            sample_weights['action_'+str(i)] = np.where(np.sum(y[i], axis=1) == 0, 0, b_ISWeights)\n",
    "        \n",
    "        train_loss = self.model.train_on_batch(X, y, sample_weight=sample_weights)\n",
    "        \n",
    "        pred = self.model.predict(X)\n",
    "        loss = self.loss(y, pred)\n",
    "        \n",
    "        self.memory.batch_update(b_idx, loss)\n",
    "        self.training_losses.append(train_loss)\n",
    "        \n",
    "        if self.model_weights_dir:\n",
    "            self.model.save(self.model_weights_dir)\n",
    "        \n",
    "        if self.train_counter % 1000 == 0:\n",
    "            self.target_model.set_weights(self.model.get_weights())\n",
    "            \n",
    "    def reshape_single_obs(self,obs):\n",
    "        \"\"\"\n",
    "        Reshapes a single observation to fit the model.\n",
    "        \"\"\"\n",
    "        return obs.reshape(1,-1)\n",
    "    \n",
    "    def loss(self, y_true, y_pred):\n",
    "        y_true = np.vstack(y_true).reshape((32, self.num_actions, self.num_atoms), order='F')\n",
    "        y_pred = np.vstack(y_pred).reshape((32, self.num_actions, self.num_atoms), order='F')\n",
    "        logloss = -np.sum(np.sum(y_true * np.log(y_pred), axis=-1), axis=-1)\n",
    "        return logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AIAgent(train=True, model_weights_dir='model_advanced.h5', use_pretrained=False)\n",
    "\n",
    "for _ in range(50):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = agent.act(observation)\n",
    "        print(action, end='\\r')\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        \n",
    "        reward = abs(observation[1])**2\n",
    "        agent.save_memory(observation, reward, action, done)\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MountainCar](mountain_car.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "%config InlineBackend.figure_format = 'png'\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(agent.training_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
